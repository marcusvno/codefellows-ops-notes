# Partner Power Hour 02 - Zero Trust Cybersecurity: Trust nothing, Protect Everything

Thank you very much, Sean, and good afternoon, everybody. Thank you for joining on a rainy Saturday here in Seattle. It's a real pleasure and honor to be here with you all, and I hope you find the chat informative. With this size of the group, feel free to ask questions throughout the discussion; either the chat or the Q&A works just fine. I have it up on my screen, so I'll be able to see it.

Today, I wanted to chat about a new concept in security called Zero Trust, and if there's time at the end, I've got a 10-minute quickie session on how to hack any computer in about five minutes or less. So for anybody that's interested, we might have time to get to that. So first, let me just jump in. For me, I'm Alex Cenaris, the CEO of Polyverse Corporation. I'm originally from Alabama, so if you hear a touch of accent, that's where it's coming from. That picture there is taken just a few blocks down from my childhood home. So I figured on a nice rainy day, this would be a good way to kick things off.

My claim to fame, historically, was being Bill Gates's technology advisor. I was also an engineer on Windows and one of the folks who wrote all the typing codes—anyplace you type, copy-paste, drag-drop, etc., on a Windows computer, that's my code. I've done five startups so far, done both the big company thing and the small company thing, and for the last six years, now actually almost seven, I've been hard at work on cybersecurity.

If we think about cybersecurity historically, it's been rooted in a very fundamental assumption, and that assumption was that you could assume perfection. There were always all these recommendations and things you had to do: keep your patches up to date, keep your virus signatures up to date, keep all your AI models trained, come up with some crazy password policy, and make sure you've got uppercase and lowercase and exclamation points, and do all this stuff. And if only you do all this stuff, oh, and watch it 24x7, then you're going to be safe.

So it really was rooted in this idea, kind of everything we were doing in cybersecurity was rooted in this idea: if you just try harder, you're going to be fine. Well, obviously, 2020 was a watershed year, and that assumption proved to be entirely false. I think most of you on this call probably know or have heard of the SolarWinds hack, but if you haven't, this was an attack where the Russians put a backdoor into a product from a company called SolarWinds. This was a cybersecurity tool, and it was used by over 18,000 organizations, including, very notably, the United States government and Microsoft itself. And so with this backdoor, the Russians had full access to pretty much everything in these organizations. We still don't know the full extent and impact of the hack, but what we do know so far is that this attack was completely undetected for over nine months. So if you think about that for a moment, you have 18,000 companies, 18,000 security teams, 18,000 deployments of Microsoft Defender and Palo Alto and FireEye, and nobody sees this, nobody finds it. If there ever was a stunning indictment and sort of watershed moment in the history of cybersecurity, this was one. I mean, quite simply, the traditional approaches failed.

And so what I want to walk through is a newer model for how to do it, but before we get there, 2020 was not just notable for the SolarWinds hack. Another big phenomenon happened, which I think all of us know very intimately now, which is why we're doing this over Zoom versus in person. That obviously is the coronavirus and the lockdowns and the whole shift to work from home, school from home, work from home, and so forth. And from a cybersecurity perspective, the key and dramatic impact there was the demise of the firewall. Previously, you could have this idea of saying, "Hey, we can protect stuff by having a private network that we put in our corporate office, and we're going to surround that network with this big castle wall called a firewall, and everybody has to go physically to the office to get access to everything."

So that whole concept of a castle wall, that firewall, when everybody's working from home, obviously that goes straight out the window and just doesn't work. And so there was a large-scale "oh gosh" moment for a lot of IT departments last year, where they just realized between that and the SolarWinds attack, what we were doing just wasn't working. Our assumptions about how security could work just aren't right. We don't have complete control over every computer; we don't have control of where it's logged on from; it could be home,

 Starbucks, wherever. We can't fix all the bugs; we can't analyze all the network traffic perfectly; we can't pick a perfect password. It just is not possible to achieve perfection.

In fact, this has been mathematically proven by a gentleman named Alan Turing. If you've ever seen the movie "Imitation Game" with Benedict Cumberbatch, great movie by the way, it goes into the invention of one of the original computers. Alan Turing, in addition to inventing one of the original computers, he also came up with a theory of computation, a mathematical formulation for how computers even work. And in that formulation—I'll skip the deep math of it—but the punchline of it is everything is going to have bugs. You cannot build any non-trivial system without having some kind of bug in there. It's sort of provable that you'll always have a bug. So if you take that as a foundational truth, then why are we trying to get to perfection, right? It's never going to happen.

So Zero Trust security is a complete change of mindset for cybersecurity, which basically starts with a different premise, and that different premise is: assume the bug, assume imperfection, assume you're going to have problems, and then ask the question, well, what do you do about it? And that gets to this notion of "trust nothing, protect everything." And you can take this "assuming imperfection" concept to literally the whole spectrum of IT operations, in authentication and how people log on to systems and use passwords, how the software itself is running, how you handle your data, how you handle your networking. I'm going to go into a little bit more detail about how all these pieces work, but it's a very simple idea of saying: look at everything you're doing in your computing environment, your IT environment, and just ask the question, what happens if this is compromised? What happens if I can't trust it? How do I provide a defense?

Well, the defense idea is pretty simple. If we know that everything will have flaws, everything will have bugs, and we know that attackers are exploiting those bugs, well, if we can't get rid of the bugs, maybe what we can do is make the cost of the exploit higher. And this is known as the polymorphic principle in computer science. And the basic idea is very simple: you will get security when the entropy in a system is greater than the amount of information leakage. In other words, if it's more expensive for an attacker to figure out what's there and actually act on it than what they're able to learn, then they're not going to be able to affect the attack. And the simple example I would give here, just the very lay analogy, is the kids' game of dodgeball. I imagine most people on this Zoom call have played dodgeball as a kid. And if you haven't, it's the game where you have a bunch of balls in the middle, two teams of, you know, grade schoolers, and the idea is you pick up a ball and you gotta throw it at somebody. If you get hit by a ball, then you're out, and if you catch it, then the thrower is out.

So if you ever played dodgeball, you know that if you just stand still, you better be really good at catching the ball because if you're just standing still, you're going to get beamed, you're going to get knocked out. So the only way to really succeed and win a dodgeball is not surprisingly to dodge, move around, keep it active, make yourself harder to hit. And that's the whole idea behind polymorphic, you know, the sort of polymorphic principle: keep things moving around, make it hard for the attacker to guess or to figure out or to somehow act upon you.

Now this sounds like a very exotic idea, but in fact, we do it all the time. This idea has been put into practice in a large-scale way already with multi-factor authentication, where you try to log onto a system, and you get a one-time password. In the old days, you sort of think about the '90s and early 2000s, I remember when I was at Microsoft at that time, and the big thing for our corporate IT shop was you got to have a good password. You know, you got to have uppercase and lowercase and an exclamation point and all this stuff. And looking back on it now, we were kind of silly because none of that stuff mattered. If your password is ever stolen, you would lose everything. So an attacker could come in impersonating you and have full control and full access. And these days, you can buy databases of passwords, literally a hundred bucks for a billion. I mean, it's a billion passwords for 100 bucks. It's crazy how cheap they are and how much, you know, over the years, these passwords have been stolen. So just trying to do

 a better password really doesn't work because it violates the polymorphic principle. If you leak it just once, then you're done, right? Because there's no changing; it's a static password.

Obviously, multi-factor authentication, even if it's just six numbers coming to you as a text, those six numbers are constantly changing. There's only a million possibilities, but if it's constantly changing and it's a one-time use in a short window of time, good luck to the attacker, right? And that's why it's an effective technique because the attacker can't guess in time for that person for that exact login exactly what that number is going to be. But again, keep things moving, keep it dynamic, faster than the attackers can go there. If you haven't implemented multi-factor authentication, there's some—I'll give a shout-out to a local Seattle company, Auth0. Multi-factor authentication used to be incredibly difficult to implement; they've done a brilliant job of making it simple. It takes about 15 minutes to integrate into your website, or your mobile app, or whatever it is you're building. So great company, good local shop, and they make it really easy to do this.

So it's not just authentication, of course. The other one, and I mentioned the whole issue with firewalls and work from home, is Zero Trust networking. So as I mentioned, this whole concept of a firewall in a work-from-home environment just really doesn't make sense anymore. There is no more castle; there's no more moat or singular corporate network that you can build a wall around and defend. So perimeter defense just doesn't work anymore. And so if you can't trust that you have a firewall, you can't trust where your employees are because it might be at home or at a café or what have you, then what you can do is flip the model. Instead of trusting that once you're in, then you get access to everything, you can flip the model and say, let's individually authenticate and route every user for every service. Now that might seem super complicated, but there's plenty of companies—Zscaler is arguably the leader in this—that have made it really easy to do.

The Zscaler, not surprisingly, if you go look them up in the financial news, they've had a heck of a great 2020 because pretty much every major company in the world woke up and said, "Oh my gosh, these firewalls aren't working for us anymore, and VPNs aren't working. We need to go to a different approach."

So if you think about all the different aspects of computing—you have users, you need to log them on, you need them authenticated, get them onto their network, onto the resources, and then what are they going to do? Well, they need to process their data using software. So on the data side, this is arguably, and at least in my personal opinion, one of the most exciting areas of cybersecurity right now because there's just a ton of innovation happening. Data is a very hard thing to lock down. There's a lot of fundamental questions. If you get an email from me, how do you know that email came from me? It might be signed for me, you know, but for 30 bucks, I can go to Intertrust and get a certificate and do signed email. That's pretty easy, really easy to fake signatures and so forth, just cost a few bucks. So is that email really from me? If I sign a contract, did I really sign it?

One of the neater technologies out there is blockchain, which of course is the underlying technology behind Bitcoin. I presume pretty much everybody's heard of Bitcoin. It's been in the news quite a lot, but if you haven't, it's a digital currency. And one of the key things that they had to solve to have a digital currency is how do you prove that if I have a dollar, a Bitcoin, that it's really mine? Because normally a digital asset, like a picture or a video of cats or something, that's easy to copy and share. So blockchain is the underlying technology that lets you prove that if I have an asset like a digital coin, that it really belongs to me. And it proves it through a mechanism of effectively a publicly auditable distributed ledger. So it's basically just a list of who owns what, what transactions happen that the entire world can see, audit, and verify. And by having that broadly dispersed verification, it makes it really hard to hack.

And it's a little unclear exactly how this is going to evolve, but I'm pretty confident over the next say decade, we're going to see a lot of innovation in blockchain and similar technologies. Of course, there's about 200 different blockchain-like technologies, so whether the blockchain-Bitcoin combo is the one that wins, or it's Ethereum, or it's Varus Coin, or one of these other ones, don't know.

 But there's a lot of very smart people working on it.

If you want to get a little more exotic, you've got things like homomorphic encryption, differential privacy, quantum-proof encryption, and so forth. Maybe two that I'll comment on now, just seeing one of the comments in the chat, one is the quantum encryption. If you look at the existing encryption algorithms like the SHA algorithm and so forth or RSA, all of those are vulnerable to attacks by quantum computers because effectively, at the core, they rely on multiplying two prime numbers together. And if those numbers can be guessed or computed, as in with a quantum computer, then you can break the encryption. So there's a whole new field of quantum-proof encryption algorithms. It is incredibly hotly contested, so I'm not going to say which algorithm I think is going to win, but I think over the next decade, just like with blockchain, we're going to see a wholesale shift to a new set of encryption technologies because we know that our current encryption technologies can be broken. So we'll have to change out the technology and change every single document that's been encrypted in the past; they're going to have to be re-encrypted with something new.

Speaking of encryption, some of the coolest stuff, which if you're interested in, I'm happy to do an offline deep dive, is something called homomorphic encryption. This essentially lets you compute on encrypted data. So you can give me data element A, data element B, and give it to me, and maybe I'm a hostile computer, I've been attacked, compromised, or you can't trust me for some reason. But with homomorphic encryption, you can still perform arbitrary computation on encrypted data. So any addition, subtraction, multiplication, basically run a complete program on this. So it's pretty wild. It's kind of slow right now, and I will admit the mathematics on this are at the limit of what I can personally do, but it's very cool stuff. And it's another sort of bleeding-edge area where we're seeing a ton of innovation in this overall concept of Zero Trust data.

So last but not least, I've hopefully shown you if you use blockchain or a lot of encryption, you can start protecting your data. Multi-factor authentication to protect users, some form of Zscaler type thing to go protect your networks, or Illumio—there's a lot of different companies there. And the final piece of this is, how do you protect your software?

If you look at a lot of the major cyber attacks that have happened over the last decade or more, almost all the really big ones were software attacks. Equifax was a software attack, SolarWinds was a software attack, Officer Personnel Management, US Army, the WhatsApp hack, the WannaCry, BlueKeep, Spectre, all of Sony, Target, Home Depot, all of these major breaches of Blue Cross and Blue Shield, these were all software attacks. And fundamentally, in each of these cases, the attacker exploited some flaw in the system. In the case of Equifax, it was very simply an unpatched web server. And so with that bug that they were able to discover in Apache, the attackers went in and took over the web server and started stealing all the data. So very simple attack, but again, due to this notion that it's just incredibly difficult to be perfect.

So Zero Trust software says, well, if we can't fix all the bugs, just like if we can change passwords all the time, what if we could change binaries all the time? What if we could change the script engines all the time? And there's a concept of polymorphic binaries, polymorphic script engines, and so forth that literally change all the binaries all the time and make it incredibly difficult for attackers to actually affect a software attack. And when I go into how to hack any computer, we'll show you this in action.

This is something my company knows—full disclosure—we do provide these polymorphic systems for Linux and other environments. But it's a very simple technique. Actually, on our website, we show you how to do it yourself. If you're doing any open source, you can easily build polymorphic systems yourself. You don't have to buy this, and it's a very simple idea where, right now, if you're getting Windows or Linux or something like that, you're using the exact same static version of Windows that all the attackers have. So all the Russian hackers, Iranian hackers, Chinese hackers, any hacker in the world, they have the exact same copy of Windows or exact same copy of Linux that you have. If they have the exact same copy, then eventually they're going to figure out how to hack you. And the attacker only has to be right once if you're a static system. If you're using the same thing, the attacker only has to be right once. They can be wrong a million times, and it doesn't matter. And as the defender, you

 have to be right all the time. So the whole idea, going back to this polymorphic principle, is to flip it. Make it so the attacker has to be right all the time, and you know that you're going to be wrong all the time because, like I said, Alan Turing has proved that.

So with that, hopefully, I've covered a little bit of the landscape of Zero Trust software. Happy to go into how to hack any computer, but before I do that, I see a couple of questions. So why don't we pause here for just a minute, and let me get to some of the questions.

Oh, it looks like I had no idea that you all had an encryption class today, so I'm glad my timing was worked out well there. Maybe one thing I should add on, even though the current encryption algorithms are vulnerable to quantum attacks, please, if you have sensitive data, encrypt it. If you've ever heard of an attack called Cambridge Analytica, which was an issue with Facebook, that was not a cyber attack. This was Facebook's business model. If you put your data on Facebook, it's public, and they're going to sell it. They're going to protest mightily that it's not quite selling your data, but let's be clear: their business model is selling your data. If your data is on Facebook, it's public. If you want your data to be private, please encrypt it.

Let's see, so questions here, with multi-factor, does authentication restrict you from being able to use encryption algorithms? And does the password restrictions mitigate the potential for a breach? Let me start with a couple of different questions in there, but let me answer it this way: it is very easy to break a password because you can simply brute force it. Let's say you only have an 8-character password. I forget the exact numbers, but you can Google it and find it. Please don't quote me on it, but it's something like 10 minutes to break an eight-character password, regardless of the characters in it and the complexity of it because computers these days are just so vast that you can brute force attempt every password out there. And the way that you do this is these passwords are stored somewhere because the password has to be checked. And so as the attacker, what you do is you just go in, and you steal the password database, and then you just brute force to figure out the password. And then you have the password, then you can log in. And if you're too lazy to brute force it, then just buy it off the dark web and go try one of the billions and billions of passwords that you can get off the internet.

And one of the sad truths of the world is that most people reuse their passwords. And so they'll use the same password for a long time. They might think they're clever, like, "Oh, I have this great password. It's 10 characters long; it has an exclamation point," etc., etc. But if you use it on 100 websites over 10 years, all it takes is for one of those websites to be compromised, have that password end up in one of these dark web databases, and then it's game over for you. So you really do need to use a multi-factor type authentication system because the cost of losing a password, even if it's difficult to guess, is just too high.

So as a side note, when I work with various companies, one of the ways that I know who has a good security department and who doesn't is I look at their password policy. And if their password policy is eight characters long and use an exclamation point, I know that this is a security team that does not understand security.

So let's see, next question, for homomorphic encryption to compute, does it need access to the public key? No, that's the brilliant part of it. You actually don't need to know anything about the encryption. You do need to have the encryption done in a very special way, and that's the kind of mathematics of it. IBM has published a really neat open-source toolkit for homomorphic encryption. My apologies, the name of it is escaping me at the moment; it's a three-letter acronym. So if you want to play around with it, go check out IBM stuff, and there's some neat little library that will let you get into it, and you can see exactly how the flow and so forth works.

So there's a question on how does this contrast to the older use of fobs that generated a 15-digit authentication. It doesn't. I assume this question relates to multi-factor authentication. If you have a text message to your phone, that counts. You can also use Google Authenticator as basically a phone-based fob, or a regular fob works just as well. One of the things that I've found in practice is that the phone-based tools are better and more convenient. You've got

 to really, when you think about being a practitioner of cybersecurity, you really got to pay attention to the social factors. I won't name which company I was working with, but a few years ago, I literally went into this company who was using a key fob, and the thing was so annoying to use that literally every employee had their key fob taped to the monitors on their desk. And so, of course, if you want to go hack into that company, all you had to do is come in with the janitorial staff, and you would have full access to everything, just because the key fobs were so annoying they just taped them to the monitors. So you really want the second factor to be something that's kept on the person in a very ergonomic fashion, like the phone is a pretty good choice.

Another question is, does having polymorphic binaries lead to an increase in bugs since you have more versions of your software? Fabulous question there. So the short answer is no, not in general. So what polymorphic software does is really changing around the underlying binaries. So for those of you on the call that have done things like assembly programming, you know what CPU registers are—EAX, EBX, ECX, and so forth. I'm willing to bet most people on this call don't know what CPU registers are. So if we're changing around which register is it, it doesn't really matter which one is being used because they're all pretty much interchangeable. So with polymorphic software, it runs the same, performs the same; as the legitimate user, you cannot tell the difference. But if you're the attacker and you're trying to steal credit card data, well, you really need to know exactly where that credit card data is. You need to know that that data is in register EAX or EBX or ECX, and so forth. And if that changes on you, then your attack fails. And that's what I can show you coming up here.

So let's see, there are a couple more questions, but maybe just for time, maybe force just to time in the chat. I can either keep going on questions or I can do a 10-minute show-and-tell on how to hack any computer. So I will defer to the audience here, so maybe just folks, just—alright, that's coming in pretty clear. So alright, let's do it. This is pretty fun.

So this is how to hack any computer. So the first bit of this is the 20 questions game. I want to set up a little bit of philosophy for it. So I think most people played 20 questions at some point when you're a kid, or you're in college or something like that. And if you haven't, it's a very simple game. You're at a dinner party or something, and you say, "I'm thinking of a word," and all your friends have 20 questions to ask to figure out what you're thinking of. So you think of a secret, and it's a pretty straightforward binary search. You say, "Is it a person or a thing?" "Okay, if it's a person," "Is it a person alive or dead?" And you just start asking these narrowing questions, and it's usually pretty easy and pretty quick to get to figure out what somebody is thinking of, if you can ask the right 20 questions. Of course, there's not much surprise here. If you think about the binary mathematics and how computers work, we can represent ginormous numbers with just 64 bits. Just ones and zeros can still represent quadrillions of different things.

So the fundamental way that you want to do an attack is literally playing 20 questions. And this is, as you probably all know from your classes, this is known as the reconnaissance step. "Is my target running Windows?" "Oh yes." "No, okay, they're running Linux." "Alright, did they deploy this patch?" Actually, the current one right now in Linux is a sudo patch. "So did they get the sudo patched?" "Oh no, great, alright, I own them now because I know how to get to root because I can send in some data, take over the sudo command, which gives me super user privileges, which gives me root, and now I own the computer." So you're just literally asking these 20 questions, and in some cases, you get there really quickly. If you're running an unpatched Windows computer, boom, you're gonna own that thing in seconds. It's pretty easy to hack Windows. Equifax, that was a very quick discovery. "Oh, they're running Apache on Linux." "Oh, it's unpatched." "Boom, gotcha." So they only had to ask three questions before all of Equifax was owned.

But still, it's this 20 questions game, just keep narrowing down the search, and you're going to get to the

 answer. So in that spirit, there's a whole class of attacks known as information leakage-based attacks, and this goes by blind ROPs, JIT sprays, Meltdown and Spectre, there's a whole bunch of different names and a whole bunch of different specific techniques, but they all fundamentally rely on this idea that if I observe a system, I can learn something about that system. And if I'm patient enough, I can learn enough to attack it. And as it turns out, I can attack a system just by watching API calls. Now everything has API calls—a website is making HTTP requests, that's an API call. If you've got an app running on your phone, that app is making API calls to the kernel. Everything makes API calls, that's kind of the way software works. And fundamentally, you cannot avoid this. Every API call leaks some information because every API call is going to either succeed or fail, or it might time out. For the example I'm going to give today, we can ignore the timeout case; I only need success or failure. And that's enough to learn what's going on in a system, just success or failure.

And fundamentally, you cannot get around that, right? It's always going to do something; it's an API call; it has to succeed, or it has to fail. So here's what I do. I start with a bug. Since we are coming up on time, I'll have to go a little bit faster through this. I won't ask you to find the bug, but as an exercise for the reader, the bug is actually here. This is just a traditional stack overflow bug. I'm going to basically end up overflowing the buffer that's on the stack, the struct user buffer. And for those of you that have gotten into how to actually affect a software attack using a stack overflow, buffer overflow, you know that the key thing you want to do is take advantage of that overflow, overflow the stack, change the return pointer or the stack pointer. And once you change the stack pointer, you have control of what's known as EIP, the instruction pointer. And once you control the instruction pointer, you control everything. For folks who are on the call who aren't doing that level of coding, think of it like mind control. The computer is basically always running around performing a set of instructions; it's running the software. And if I can change which instructions are being run, then I can control the computer using the software that's already there. That's why I call it mind control because everything I need to attack is already there. This computer already knows how to get to the database; it knows how to decrypt credit cards; it knows how to log in and knows how to do all this stuff. So if I can just control the functionality that's already there, then I'm in great shape. So that's why these attacks are so devastating because it really is a mind control.

And so not surprisingly, a lot of people understood this for a while, and the major operating systems like macOS and Windows and Linux have a defense technology called a stack canary. And a stack canary is a very simple idea. Let's make up a magic number, and we'll put that magic number on the stack. So if somebody's trying to mess with me to change things around, they will have to end up changing that magic number. So I'll just check the magic number, and if it's changed, then I know that I've been attacked. A very simple idea. In this case, the magic number can be anything. In this case, I chose 42. Hopefully, everybody on the call knows the importance of 42. But whatever the number is, I just put a magic number on the stack and so forth.

So you would think, absolutely, Amber, it's the answer to the ultimate question of life, the universe, and everything. As the attacker, how do I figure out a 64-bit number? There are quadrillions of possibilities; I can't guess that. Well, as it turns out, I can. And actually, I can guess this number and break this defense in less than 4,000 tries. And the way I do it is I don't try to guess a full 64-bit number; I just try to guess the first byte. And all I need to do is again take my overflow and instead of overflowing everything, I'm just going to overflow by one byte. And I'm going to try the value zero, and then I'm going to try the value one, and then I'm going to try the value two. And every time I try this, I'm guaranteed to get back some answer. I'm guaranteed to either get back a success or a failure.

Now in the case if I try a one, I'm going to get back a failure because the magic number is 42. But I need to try 256 times, and eventually, I'm going to

 get to the right number. So I'm going to crash, crash, crash as I go from one, two, three, and I'm going to get to four, and that's going to succeed. Now I know the high order byte. So I'm going to try again on the second highest order byte, and we'll try one, and we'll go all the way up to 255. In this case, just going up to two is sufficient. So I'm just going to keep trying and try and try and bite at a time. So all I need to do is do 256 tries per byte, and I can just guess, and eventually, I'm going to guess the entire number. And once I do that, and it's about four thousand tries, this really great work from Stanford—just Google for a paper called "Hacking Blind"—will give you all the details of this. But the punch line is if I just try a few times—and again, all I'm taking advantage of is the information leakage of success or fail—success or fail is enough for me to learn enough about your system to take it over if it is a static system. And this is the key bit, and why I emphasize that polymorphic principle because if you are changing the canary, or you're changing the binaries, or you're changing anything about the system while somebody's doing those four thousand attempts, it's going to break; the attack is going to fail.

So you know that you've got a window now with sort of modern techniques where you've got to be changing faster than every four thousand calls. If you do that, you're going to win. If you're curious and want to learn more about this, I have it—we've put up an interactive tutorial; you can see all the source code; you can see; you can play with the attack; there's a vulnerability; everything I just walked you through is live on the web for you. Just go to polyverse.com/learn-blind-rop, and feel free to play around with it and see what you think. But you can actually do a real live attack on this. So yeah, bang away at it and see what you can do. And then put on the polymorphic defense and see if you can actually break it.

So anyway, with that, let me pause there. I think I'm at my time, or three minutes to go. So I hope folks found this interesting and informative, and let me go over to some questions here. Oh, so we have a Ferris Bueller in the audience who asked, "Can I modify my midterm grades?" Maybe I'll try to find a—there's a very famous joke in cybersecurity for midterm exams on cybersecurity. And the exam is "Your grades are posted on a server. You all have failed. I will be publishing the grades tomorrow at noon." That's it. That's the exam. So you've got until tomorrow at noon to go hack the server. Thankfully, my university classes were not quite that hardcore. But that always struck me as the perfect cybersecurity exam.

All right, a couple more questions. Let's see, if my life depended on it, how would I go about trying to crack a decrypt hash? Just brute force it. I mean, there's enough compute power these days; just go for it. You don't really need to do much more than that these days. Parrot or Kali? Hmm, I'm kind of old school myself; I like Kali Linux. There's a bunch of stuff in there. But you know, kind of the thing to maybe think about with cybersecurity is just always be learning. Whatever you think you know about cybersecurity, whatever I thought I knew six years ago, has been a bunch more stuff since then. Ten years ago, I thought I understood encryption, and now with quantum computing, oops, gotta go learn some more stuff. So just always have that learning mindset. So while I like Kali, yeah, try all the other stuff too.

What professional cybersecurity accomplishment in my career am I most proud of? That's one—I'm sure there actually is one. This was my think week for the summer. I wrote a data scrambler. So if you think about all this polymorphic stuff we just talked about, where we're constantly changing things, we know now how to change passwords all the time; we know how to change the software all the time; we can keep a lot of things dynamic. But up until the summer, we didn't know how to change data all the time. So I took about a week off, and I wrote a system that constantly changes the data in memory and continuously encrypts and re-encrypts it with different encryption keys on every memory access or every memory change. And it does it with about a five percent overhead. So it's an incredibly fast system, and it's for the first time, to my knowledge, anybody's ever pulled off continuously polymorphic data in the kernel

. So I had a lot of fun writing that. I promptly gave it to my team; they said my code was full of—sorry, that's a technical term—and then they rewrote it and made it to be a pretty good system. So we'll be shipping that this coming year. But that's one that I'm personally kind of proud of, just because it was a tough problem that stumped many people for decades. So we finally kind of had the aha moment and got it going.

I assume most servers only store the hash password; can a hacker retrieve the original password from the hash password? Yes, that's the problem. So you're very correct; most servers will store the hashed password. Every now and then, you'll come across somebody who only stored the plaintext password, and you just kind of go, "What were you thinking?" It happens. But most of the time, you will store this salted hash password. But again, if I get access to that, easy to break with brute force because, like I said, I forgot the exact number of minutes it takes to break a typical password, but it's literally measured in minutes. So I just stand up a bank of computers; it's a perfectly parallel task, and I just buzz through and go break all the passwords by brute force if I need to because it's cheap and easy to do these days. When you think about a couple of minutes of compute time, is these days what is that worth in Amazon? One-hundredth of a penny? So you can break hundreds of passwords for a couple of pennies worth of cost. Not hard to do.

I think that covers more messages on the bottom here. I think I've covered all the pending questions and from the chat. If I missed one, let me maybe just re-put it up, or Sean, did I miss anything here?

Nope, you did a great job going through them all. Tried to keep it all cleared out for you, so you didn't accidentally get an extra one. Thank you so much for your time over the last two days. It's been a really great conversation; I'd love to see these talks and how they develop over day to day. So thank you for your time, thanks for staying after and answering all those questions as well.

Yeah, my pleasure is a real pleasure to meet everybody. Thank you very much for your time and attention on Saturday, and as I said, feel free to reach out anytime with questions or comments or further discussion.

Absolutely, thank you. Have a great weekend.

Thanks, everybody.